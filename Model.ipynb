{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kivsithvothy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kivsithvothy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kivsithvothy/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of tweet</th>\n",
       "      <th>id of the tweet</th>\n",
       "      <th>date of the tweet</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text of the tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186342</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Madelinedugganx</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186409</td>\n",
       "      <td>Fri May 29 07:33:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>OffRoad_Dude</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186429</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Falchion</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186445</td>\n",
       "      <td>Fri May 29 07:33:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jonasobsessedx</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>4</td>\n",
       "      <td>1960186607</td>\n",
       "      <td>Fri May 29 07:33:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sugababez</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity of tweet   id of the tweet             date of the tweet  \\\n",
       "0                         0       1467810672  Mon Apr 06 22:19:49 PDT 2009   \n",
       "1                         0       1467810917  Mon Apr 06 22:19:53 PDT 2009   \n",
       "2                         0       1467811184  Mon Apr 06 22:19:57 PDT 2009   \n",
       "3                         0       1467811193  Mon Apr 06 22:19:57 PDT 2009   \n",
       "4                         0       1467811372  Mon Apr 06 22:20:00 PDT 2009   \n",
       "...                     ...              ...                           ...   \n",
       "1048567                   4       1960186342  Fri May 29 07:33:44 PDT 2009   \n",
       "1048568                   4       1960186409  Fri May 29 07:33:43 PDT 2009   \n",
       "1048569                   4       1960186429  Fri May 29 07:33:44 PDT 2009   \n",
       "1048570                   4       1960186445  Fri May 29 07:33:44 PDT 2009   \n",
       "1048571                   4       1960186607  Fri May 29 07:33:45 PDT 2009   \n",
       "\n",
       "            query             user  \\\n",
       "0        NO_QUERY    scotthamilton   \n",
       "1        NO_QUERY         mattycus   \n",
       "2        NO_QUERY          ElleCTF   \n",
       "3        NO_QUERY           Karoli   \n",
       "4        NO_QUERY         joy_wolf   \n",
       "...           ...              ...   \n",
       "1048567  NO_QUERY  Madelinedugganx   \n",
       "1048568  NO_QUERY     OffRoad_Dude   \n",
       "1048569  NO_QUERY         Falchion   \n",
       "1048570  NO_QUERY   jonasobsessedx   \n",
       "1048571  NO_QUERY        sugababez   \n",
       "\n",
       "                                        text of the tweet   \n",
       "0        is upset that he can't update his Facebook by ...  \n",
       "1        @Kenichan I dived many times for the ball. Man...  \n",
       "2          my whole body feels itchy and like its on fire   \n",
       "3        @nationwideclass no, it's not behaving at all....  \n",
       "4                            @Kwesidei not the whole crew   \n",
       "...                                                    ...  \n",
       "1048567           My GrandMa is making Dinenr with my Mum   \n",
       "1048568  Mid-morning snack time... A bowl of cheese noo...  \n",
       "1048569  @ShaDeLa same here  say it like from the Termi...  \n",
       "1048570             @DestinyHope92 im great thaanks  wbuu?  \n",
       "1048571               cant wait til her date this weekend   \n",
       "\n",
       "[1048572 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv', delimiter=',', encoding='ISO-8859-1')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Sentiment','id','date','query','user','text']\n",
    "df = df[['Sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>4</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>4</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>4</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>4</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>4</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                               text\n",
       "0                0  is upset that he can't update his Facebook by ...\n",
       "1                0  @Kenichan I dived many times for the ball. Man...\n",
       "2                0    my whole body feels itchy and like its on fire \n",
       "3                0  @nationwideclass no, it's not behaving at all....\n",
       "4                0                      @Kwesidei not the whole crew \n",
       "...            ...                                                ...\n",
       "1048567          4           My GrandMa is making Dinenr with my Mum \n",
       "1048568          4  Mid-morning snack time... A bowl of cheese noo...\n",
       "1048569          4  @ShaDeLa same here  say it like from the Termi...\n",
       "1048570          4             @DestinyHope92 im great thaanks  wbuu?\n",
       "1048571          4               cant wait til her date this weekend \n",
       "\n",
       "[1048572 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/7f20ppnx1tndyhj_ryqldllm0000gn/T/ipykernel_29550/3571630867.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment'] = df['Sentiment'].replace({4:1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>1</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>1</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>1</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                               text\n",
       "0                0  is upset that he can't update his Facebook by ...\n",
       "1                0  @Kenichan I dived many times for the ball. Man...\n",
       "2                0    my whole body feels itchy and like its on fire \n",
       "3                0  @nationwideclass no, it's not behaving at all....\n",
       "4                0                      @Kwesidei not the whole crew \n",
       "...            ...                                                ...\n",
       "1048567          1           My GrandMa is making Dinenr with my Mum \n",
       "1048568          1  Mid-morning snack time... A bowl of cheese noo...\n",
       "1048569          1  @ShaDeLa same here  say it like from the Termi...\n",
       "1048570          1             @DestinyHope92 im great thaanks  wbuu?\n",
       "1048571          1               cant wait til her date this weekend \n",
       "\n",
       "[1048572 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace value 4 with 1 for positive sentiment\n",
    "df['Sentiment'] = df['Sentiment'].replace({4:1})\n",
    "\n",
    "# Downsample the majority class to balance the dataset\n",
    "df_majority = df[df['Sentiment']==0]\n",
    "df_minority = df[df['Sentiment']==1]\n",
    "df_majority_downsampled = df_majority.sample(n=len(df_minority), random_state=42)\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    # Original: running, Lemmatized: running\n",
    "    # Original: ate, Lemmatized: ate\n",
    "    # Original: dogs, Lemmatized: dog\n",
    "    # Original: better, Lemmatized: better\n",
    "    # Original: rocks, Lemmatized: rock\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]  # Lemmatization\n",
    "    # For stop_words\n",
    "    # Original text: This is an example sentence to demonstrate removing stopwords.\n",
    "    # Filtered text: example sentence demonstrate removing stopwords.\n",
    "    return ' '.join(text)\n",
    "\n",
    "df_balanced['text_cleaned'] = df_balanced['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212188     amruth92 early bird didnt reply facebook wall ...\n",
       "674330     sooo hot tonight wish pool id outside skinny d...\n",
       "752234                            darkandrez washing clothes\n",
       "415739                                        asexiness suck\n",
       "138859     havent watch yet finale ai ive waiting replay ...\n",
       "                                 ...                        \n",
       "1048567                            grandma making dinenr mum\n",
       "1048568         midmorning snack time bowl cheese noodle yum\n",
       "1048569    shadela say like terminiator movie come like 3...\n",
       "1048570                  destinyhope92 im great thaanks wbuu\n",
       "1048571                           cant wait til date weekend\n",
       "Name: text_cleaned, Length: 497152, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['text_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>1</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>1</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>1</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                               text\n",
       "0                0  is upset that he can't update his Facebook by ...\n",
       "1                0  @Kenichan I dived many times for the ball. Man...\n",
       "2                0    my whole body feels itchy and like its on fire \n",
       "3                0  @nationwideclass no, it's not behaving at all....\n",
       "4                0                      @Kwesidei not the whole crew \n",
       "...            ...                                                ...\n",
       "1048567          1           My GrandMa is making Dinenr with my Mum \n",
       "1048568          1  Mid-morning snack time... A bowl of cheese noo...\n",
       "1048569          1  @ShaDeLa same here  say it like from the Termi...\n",
       "1048570          1             @DestinyHope92 im great thaanks  wbuu?\n",
       "1048571          1               cant wait til her date this weekend \n",
       "\n",
       "[1048572 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889926            finally uploading crappy britney spear pic\n",
       "420864             flying back dubai 6pm philippine time sad\n",
       "86095      faeorie nah dunno viv green think neighbourhoo...\n",
       "926275     mcds kid mom nap think im getting better end m...\n",
       "1017241    fruitty pebble organic milk really cheer espec...\n",
       "                                 ...                        \n",
       "810598                       another amusing tweeter tinafey\n",
       "917258                         michaelmcrowley saw wolverine\n",
       "274021                                          losing voice\n",
       "60643      settled watch football realised dont get setan...\n",
       "395703         lookin french article oral exam hope graduate\n",
       "Name: text_cleaned, Length: 397721, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['text_cleaned'], df_balanced['Sentiment'], test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kivsithvothy/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.78\n",
      "Testing Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_accuracy = lr_model.score(X_train_tfidf, y_train)\n",
    "test_accuracy = lr_model.score(X_test_tfidf, y_test)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classification report of a logistic regression classifier using the classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77     49666\n",
      "           1       0.77      0.79      0.78     49765\n",
      "\n",
      "    accuracy                           0.77     99431\n",
      "   macro avg       0.77      0.77      0.77     99431\n",
      "weighted avg       0.77      0.77      0.77     99431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Predict the target values\n",
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Display the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for training and testing ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy       Dataset\n",
      "0  0.781125  Training set\n",
      "1  0.773803      Test set\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with the accuracy scores\n",
    "accuracy_scores = pd.DataFrame({\n",
    "    \"Accuracy\": [train_accuracy, test_accuracy],\n",
    "    \"Dataset\": [\"Training set\", \"Test set\"]\n",
    "})\n",
    "\n",
    "# Print the dataframe\n",
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the split percentage of training and test set as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Dataset  Percentage\n",
      "0  Training set          80\n",
      "1      Test set          20\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with the split percentages\n",
    "split_percentages = pd.DataFrame({\n",
    "    \"Dataset\": [\"Training set\", \"Test set\"],\n",
    "    \"Percentage\": [100 - 20, 20]\n",
    "})\n",
    "\n",
    "# Display the dataframe\n",
    "print(split_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    polarity of tweet   id of the tweet\n",
      "polarity of tweet             1.000000        -0.571528\n",
      "id of the tweet              -0.571528         1.000000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', delimiter=',', encoding='ISO-8859-1')\n",
    "print(data.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and TF-IDF vectorizer to disk\n",
    "joblib.dump(lr_model, 'sentiment_analysis_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
